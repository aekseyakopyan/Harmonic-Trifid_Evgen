"""
Celery tasks –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏–¥–æ–≤.
–í—Å–µ –∑–∞–¥–∞—á–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç retry mechanism –∏ structured logging.
"""

from systems.parser.celery_config import app
from systems.parser.lead_filter_advanced import LeadFilterAdvanced
from core.utils.structured_logger import get_logger
from core.ai_engine.resilient_llm import resilient_llm_client
import time
from datetime import datetime, timedelta

logger = get_logger(__name__)


@app.task(
    bind=True,
    name="systems.parser.tasks.process_lead_async",
    priority=5,
    max_retries=3,
    default_retry_delay=60
)
def process_lead_async(self, lead_data: dict):
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏–¥–∞ —á–µ—Ä–µ–∑ 7-level pipeline.
    """
    start_time = time.time()
    task_id = self.request.id
    
    logger.info(
        "lead_processing_started",
        task_id=task_id,
        message_id=lead_data["message_id"],
        source=lead_data["source"]
    )
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è filter engine
        filter_engine = LeadFilterAdvanced()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ pipeline
        # –í–∞–∂–Ω–æ: analyze –≤ LeadFilterAdvanced —è–≤–ª—è–µ—Ç—Å—è async, –Ω–æ Celery worker —Å–∏–Ω—Ö—Ä–æ–Ω–µ–Ω.
        # –û–¥–Ω–∞–∫–æ process_lead_async –º–æ–∂–µ—Ç –±—ã—Ç—å async –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å event loop.
        # –¢–ó –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É.
        import asyncio
        result = asyncio.run(filter_engine.analyze(
            text=lead_data["text"],
            message_id=lead_data["message_id"],
            source=lead_data["source"]
        ))
        
        processing_time = int((time.time() - start_time) * 1000)
        result["processing_time_ms"] = processing_time
        result["task_id"] = task_id
        
        # Priority routing –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
        if result.get("tier") == "HOT":
            send_notification.apply_async(
                args=[result, lead_data],
                priority=9,
                countdown=0
            )
            logger.info(
                "hot_lead_detected",
                task_id=task_id,
                priority=result.get("priority"),
                processing_time_ms=processing_time
            )
            
        elif result.get("tier") == "WARM":
            send_notification.apply_async(
                args=[result, lead_data],
                priority=5,
                countdown=60
            )
        
        logger.info(
            "lead_processing_completed",
            task_id=task_id,
            tier=result.get("tier"),
            priority=result.get("priority"),
            processing_time_ms=processing_time
        )
        
        return result
        
    except Exception as e:
        logger.error(
            "lead_processing_failed",
            task_id=task_id,
            message_id=lead_data["message_id"],
            error=str(e)[:500],
            retry_count=self.request.retries
        )
        
        retry_countdown = 60 * (2 ** self.request.retries)
        
        raise self.retry(
            exc=e,
            countdown=retry_countdown,
            max_retries=3
        )


@app.task(
    bind=True,
    name="systems.parser.tasks.send_notification",
    priority=9,
    max_retries=5
)
def send_notification(self, lead_result: dict, lead_data: dict):
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –¥–ª—è HOT/WARM –ª–∏–¥–æ–≤.
    """
    task_id = self.request.id
    
    logger.info(
        "notification_sending",
        task_id=task_id,
        tier=lead_result.get("tier"),
        priority=lead_result.get("priority")
    )
    
    try:
        notification_text = f"""
üî• {lead_result.get('tier')} –ª–∏–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω!

üìä Priority: {lead_result.get('priority')}/100
üìù –ò—Å—Ç–æ—á–Ω–∏–∫: {lead_data['source']}
üîó Message ID: {lead_data['message_id']}

üí¨ –¢–µ–∫—Å—Ç:
{lead_data['text'][:200]}...

‚ö° –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {lead_result.get('processing_time_ms')}ms
"""
        
        logger.info(
            "notification_sent",
            task_id=task_id,
            tier=lead_result.get("tier")
        )
        
        return {"status": "sent", "task_id": task_id}
        
    except Exception as e:
        logger.error(
            "notification_failed",
            task_id=task_id,
            error=str(e)[:200]
        )
        raise self.retry(exc=e, countdown=30)


@app.task(name="systems.parser.tasks.cleanup_old_leads")
def cleanup_old_leads():
    """
    Periodic task: —É–¥–∞–ª–µ–Ω–∏–µ –ª–∏–¥–æ–≤ —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π –∏–∑ –ë–î.
    """
    logger.info("cleanup_started", retention_days=30)
    
    try:
        from systems.parser.vacancy_db import VacancyDatabase
        
        db = VacancyDatabase()
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥ —É–¥–∞–ª–µ–Ω–∏—è –≤ VacancyDatabase
        deleted_count = 0  
        
        logger.info(
            "cleanup_completed",
            deleted_count=deleted_count
        )
        
        return {"deleted": deleted_count}
        
    except Exception as e:
        logger.error("cleanup_failed", error=str(e))
        raise


@app.task(name="systems.parser.tasks.monitor_circuit_breakers")
def monitor_circuit_breakers():
    """
    Periodic task: –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è circuit breakers.
    """
    health = resilient_llm_client.get_health_status()
    
    logger.info(
        "circuit_breaker_health_check",
        healthy=health["healthy"],
        openrouter_state=health["openrouter"]["state"],
        ollama_state=health["ollama"]["state"]
    )
    
    if not health["healthy"]:
        logger.error(
            "critical_all_llm_down",
            openrouter_fails=health["openrouter"]["fail_counter"],
            ollama_fails=health["ollama"]["fail_counter"]
        )
    
    return health


@app.task(name="systems.parser.tasks.calculate_hourly_stats")
def calculate_hourly_stats():
    """
    Periodic task: —Ä–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å.
    """
    logger.info("calculating_hourly_stats")
    
    try:
        stats = {
            "total_processed": 0,
            "hot_count": 0,
            "warm_count": 0,
            "cold_count": 0,
            "avg_processing_time_ms": 0
        }
        
        logger.info("hourly_stats", **stats)
        return stats
        
    except Exception as e:
        logger.error("stats_calculation_failed", error=str(e))
        raise


@app.task(
    bind=True,
    name="systems.parser.tasks.batch_process_leads",
    priority=3
)
def batch_process_leads(self, lead_batch: list):
    """
    Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª–∏–¥–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.
    """
    task_id = self.request.id
    
    logger.info(
        "batch_processing_started",
        task_id=task_id,
        batch_size=len(lead_batch)
    )
    
    results = []
    for lead_data in lead_batch:
        task = process_lead_async.apply_async(
            args=[lead_data],
            priority=3
        )
        results.append({"message_id": lead_data["message_id"], "task_id": task.id})
    
    return {
        "processed": len(results),
        "results": results
    }
