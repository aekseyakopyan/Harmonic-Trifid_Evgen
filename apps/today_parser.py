"""
–ü–∞—Ä—Å–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ Telegram –∑–∞ —Å–µ–≥–æ–¥–Ω—è —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –≤—Å–µ–º —á–∞—Ç–∞–º.
"""

import asyncio
import json
import os
from datetime import datetime, timedelta, timezone
from telethon import TelegramClient
from telethon.tl.types import MessageEntityTextUrl
from dotenv import load_dotenv

import sys
sys.path.append(os.getcwd())

from systems.parser.vacancy_analyzer.scorer import VacancyScorer
from systems.parser.vacancy_analyzer.contact_extractor import ContactExtractor
from systems.parser.vacancy_analyzer.niche_detector import NicheDetector
from systems.parser.vacancy_db import VacancyDatabase
from core.config.settings import settings

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

class TelegramVacancyParser:
    """–ü–∞—Ä—Å–µ—Ä –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤ –∏ –≥—Ä—É–ø–ø"""
    
    def __init__(self):
        self.api_id = settings.TELEGRAM_API_ID
        self.api_hash = settings.TELEGRAM_API_HASH
        from telethon.sessions import StringSession
        with open("data/sessions/session_string_final.txt", "r") as f:
            session_str = f.read().strip()
        self.session = StringSession(session_str)
        
        self.scorer = VacancyScorer()
        self.contact_extractor = ContactExtractor()
        self.niche_detector = NicheDetector()
        
        self.client = None
        self.seen_messages = set() # –î–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø–æ —Ç–µ–∫—Å—Ç—É
        self.db = VacancyDatabase()  # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π (–±–µ—Ä–µ—Ç –ø—É—Ç—å –∏–∑ settings)
        self.results = {
            'parsed_at': datetime.now(timezone.utc).isoformat(),
            'total_messages_scanned': 0,
            'total_chats_scanned': 0,
            'relevant_vacancies': [],
            'irrelevant_messages': [],
            'all_messages': [] # –î–ª—è –ø–æ–ª–Ω–æ–≥–æ –¥–∞–º–ø–∞
        }
    
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Telegram –∫–ª–∏–µ–Ω—Ç–∞"""
        self.client = TelegramClient(
            self.session,
            self.api_id,
            self.api_hash
        )
        await self.client.start()
        print("‚úÖ Telegram –∫–ª–∏–µ–Ω—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω")
    
    async def parse_dialogs(self, hours_ago: int = 24):
        """
        –ü–∞—Ä—Å–∏—Ç –≤—Å–µ –≥—Ä—É–ø–ø—ã –∏ –∫–∞–Ω–∞–ª—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤.
        """
        await self.initialize()
        
        print(f"\nüìÖ –ò—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤–æ –≤—Å–µ—Ö —á–∞—Ç–∞—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {hours_ago} —á–∞—Å–æ–≤...")
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω–æ –≤—Å–µ –¥–∏–∞–ª–æ–≥–∏ –±–µ–∑ –ª–∏–º–∏—Ç–∞
        dialogs = await self.client.get_dialogs(limit=None)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º: –ò—Å–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–ø–∏—Å–∫–∏ —Å –ª—é–¥—å–º–∏. –û—Å—Ç–∞–≤–ª—è–µ–º –ì—Ä—É–ø–ø—ã, –ö–∞–Ω–∞–ª—ã –∏ –ë–æ—Ç–æ–≤.
        target_dialogs = []
        for d in dialogs:
            if d.is_group or d.is_channel:
                target_dialogs.append(d)
            elif d.is_user:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±–æ—Ç –ª–∏ —ç—Ç–æ
                if hasattr(d.entity, 'bot') and d.entity.bot:
                    target_dialogs.append(d)
        
        self.results['total_chats_scanned'] = len(target_dialogs)
        print(f"üéØ –ù–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (–∫–∞–Ω–∞–ª—ã, –≥—Ä—É–ø–ø—ã, –±–æ—Ç—ã): {len(target_dialogs)}\n")
        
        for i, dialog in enumerate(target_dialogs, 1):
            chat_name = dialog.name or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
            print(f"[{i}/{len(target_dialogs)}] üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º: {chat_name}")
            
            try:
                # –í—Ä–µ–º–µ–Ω–Ω–∞—è –≥—Ä–∞–Ω–∏—Ü–∞
                time_threshold = datetime.now(timezone.utc) - timedelta(hours=hours_ago)
                
                messages_count = 0
                # –õ–∏–º–∏—Ç 100 —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–∞ —á–∞—Ç
                async for message in self.client.iter_messages(dialog, limit=100):
                    if not message.message:
                        continue
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
                    if message.date < time_threshold:
                        break
                    
                    messages_count += 1
                    self.results['total_messages_scanned'] += 1
                    
                    # –ê–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
                    await self._analyze_message(message, chat_name)
                
                if messages_count > 0:
                    print(f"   ‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {messages_count}")
                    
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {chat_name}: {e}")
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
            await asyncio.sleep(0.05)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        self.results['relevant_vacancies'].sort(
            key=lambda x: (
                0 if x['priority'] == 'HIGH' else (1 if x['priority'] == 'MEDIUM' else 2),
                -x['analysis']['relevance_score']
            )
        )
        
        await self.client.disconnect()
        print("\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")

    def _get_message_hash(self, text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Å—Ç–æ–π —Ö–µ—à –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (–∏–≥–Ω–æ—Ä–∏—Ä—É—è –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–µ–≥–∏—Å—Ç—Ä)"""
        import hashlib
        clean_text = "".join(text.lower().split())
        return hashlib.md5(clean_text.encode()).hexdigest()

    async def _analyze_message(self, message, channel_name: str):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        text = message.message
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É (–≤ —Ä–∞–º–∫–∞—Ö —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞)
        msg_hash = self._get_message_hash(text)
        if msg_hash in self.seen_messages:
            return # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç –≤ —Ä–∞–º–∫–∞—Ö —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞
        self.seen_messages.add(msg_hash)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ)
        if self.db.is_processed(text):
            return  # –í–∞–∫–∞–Ω—Å–∏—è —É–∂–µ –±—ã–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —Ä–∞–Ω–µ–µ
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–Ω–æ–ø–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        buttons_text = ""
        if message.buttons:
            buttons_text = "üîò –ö–ù–û–ü–ö–ò:\n"
            for row in message.buttons:
                for button in row:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã —Å—Å—ã–ª–∫–∏
                    link = None
                    if hasattr(button, 'url') and button.url:
                        link = button.url
                    elif hasattr(button, 'data') and button.data:
                        # –ò–Ω–ª–∞–π–Ω–æ–≤—ã–µ –∫–Ω–æ–ø–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–±—ã—á–Ω–æ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø—Ä—è–º—ã—Ö —Å—Å—ã–ª–æ–∫, 
                        # –Ω–æ –º—ã –º–æ–∂–µ–º –ø–æ–º–µ—Ç–∏—Ç—å –∏—Ö –Ω–∞–ª–∏—á–∏–µ
                        pass
                    
                    if link:
                        buttons_text += f"‚Ä¢ {button.text} ‚Üí {link}\n"
                    else:
                        buttons_text += f"‚Ä¢ {button.text} (–∏–Ω–ª–∞–π–Ω/–∫–Ω–æ–ø–∫–∞)\n"
        
        # –ü–æ–∏—Å–∫ Google Forms
        has_google_form = "docs.google.com/forms" in text or "forms.gle" in text or "forms.gle" in buttons_text
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        analysis = self.scorer.analyze_message(text, message.date)
        
        vacancy_data = {
            'channel': channel_name,
            'message_id': message.id,
            'date': message.date.isoformat(),
            'text': text[:500],  # –û–±—Ä–µ–∑–∞–µ–º –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏
            'full_text': text,
            'sender_id': message.sender_id,
            'analysis': analysis,
            'has_form': has_google_form
        }
        
        if analysis['is_vacancy']:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
            fwd_from = None
            if message.fwd_from:
                from_id = None
                if hasattr(message.fwd_from, 'from_id'):
                    f_id = message.fwd_from.from_id
                    if hasattr(f_id, 'user_id'):
                        from_id = f_id.user_id
                    elif hasattr(f_id, 'channel_id'):
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ channel_id
                        pass
                
                fwd_from = {
                    'from_id': from_id,
                    'from_username': None, # –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è username –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å GetFullUser
                    'channel_id': message.fwd_from.from_id.channel_id if hasattr(message.fwd_from, 'from_id') and hasattr(message.fwd_from.from_id, 'channel_id') else None
                }
            
            # –ü–æ–ª—É—á–∞–µ–º username –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫, –Ω–µ –∫–∞–Ω–∞–ª)
            sender_username = None
            sender_is_user = False
            try:
                from telethon.tl.types import User
                sender = await message.get_sender()
                if sender and isinstance(sender, User) and hasattr(sender, 'username'):
                    sender_username = sender.username
                    sender_is_user = True
            except:
                pass
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–∞–∫—Ç
            contact_data = self.contact_extractor.extract_contact({
                'text': text,
                'buttons': buttons_text,
                'sender_id': message.sender_id if sender_is_user else None,
                'fwd_from': fwd_from,
                'sender_username': sender_username
            })
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∏—à—É
            niche_data = self.niche_detector.detect_niche(text)
            
            vacancy_data['contact'] = contact_data
            vacancy_data['niche'] = niche_data
            # –ë—É—Å—Ç –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–π —Å —Ñ–æ—Ä–º–∞–º–∏
            vacancy_data['priority'] = self._calculate_priority(analysis, contact_data, has_google_form)
            vacancy_data['budget'] = analysis.get('budget')
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ –ø—Ä–∏–Ω—è—Ç—É—é —Å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –∏ –∫–æ–Ω—Ç–∞–∫—Ç–æ–º
            direction = analysis.get('specialization', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')
            contact_link = contact_data.get('contact_link')
            self.db.add_accepted(text, channel_name, direction, contact_link, message.date.isoformat())
            
            self.results['relevant_vacancies'].append(vacancy_data)
            
            status_icon = "üìù –§–û–†–ú–ê!" if has_google_form else "‚úÖ –ù–∞–π–¥–µ–Ω–æ!"
            print(f"   {status_icon} Score: {analysis['relevance_score']}, Spec: {analysis['specialization']}")
        else:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö
            if analysis.get('rejection_reason'):
                self.results['irrelevant_messages'].append({
                    'channel': channel_name,
                    'message_id': message.id,
                    'rejection_reason': analysis.get('rejection_reason'),
                    'score': analysis['relevance_score']
                })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ –æ—Ç–∫–ª–æ–Ω—ë–Ω–Ω—É—é
        if analysis.get('rejection_reason'):
            self.db.add_rejected(
                text,
                channel_name,
                analysis.get('rejection_reason'),
                message.date.isoformat()
            )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –í–û–û–ë–©–ï –í–°–ï –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –¥–∞–º–ø–∞
        self.results['all_messages'].append({
            'channel': channel_name,
            'message_id': message.id,
            'date': message.date.isoformat(),
            'full_text': text,
            'is_relevant': analysis['is_vacancy'],
            'relevance_score': analysis['relevance_score'],
            'rejection_reason': analysis.get('rejection_reason')
        })

    def _calculate_priority(self, analysis: dict, contact: dict, has_form: bool = False) -> str:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏"""
        score = analysis['relevance_score']
        contact_priority = contact.get('priority_level', '3')
        
        # HIGH: Score >= 6 –∏–ª–∏ –∫–æ–Ω—Ç–∞–∫—Ç 1A/1B –∏–ª–∏ –Ω–∞–ª–∏—á–∏–µ —Ñ–æ—Ä–º—ã
        if has_form or (score >= 6 and contact_priority in ['1A', '1B']):
            return 'HIGH'
        # MEDIUM: Score >= 4
        elif score >= 4:
            return 'MEDIUM'
        else:
            return 'LOW'

    def save_results(self, filename: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª"""
        filepath = settings.DATA_DIR / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filepath}")
        print(f"   üìä –í—Å–µ–≥–æ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {self.results.get('total_chats_scanned', 0)}")
        print(f"   üìä –í—Å–µ–≥–æ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {self.results['total_messages_scanned']}")
        print(f"   ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {len(self.results['relevant_vacancies'])}")

    def generate_markdown_report(self, filename: str):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π markdown-–æ—Ç—á–µ—Ç —Å —É—á—ë—Ç–æ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –ë–î."""
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        db_stats = self.db.get_stats()
        filepath = settings.REPORTS_DIR / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"# üìä –û—Ç—á–µ—Ç –ø–æ –≤–∞–∫–∞–Ω—Å–∏—è–º (–ø–æ–¥—Ä–æ–±–Ω—ã–π)\n\n")
            f.write(f"**–î–∞—Ç–∞:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
            f.write(f"**–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ:** {self.results.get('total_chats_scanned', 0)}\n")
            f.write(f"**–°–æ–æ–±—â–µ–Ω–∏–π –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ:** {self.results.get('total_messages_scanned', 0)}\n")
            f.write(f"**–ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π:** {len(self.results['relevant_vacancies'])}\n\n")
            f.write("---\n\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            f.write("### üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –≤—Å—ë –≤—Ä–µ–º—è\n\n")
            f.write(f"- **–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:** {db_stats['total']} –≤–∞–∫–∞–Ω—Å–∏–π\n")
            f.write(f"- **–ü—Ä–∏–Ω—è—Ç–æ:** {db_stats['accepted']}\n")
            f.write(f"- **–û—Ç–∫–ª–æ–Ω–µ–Ω–æ:** {db_stats['rejected']}\n\n")
            f.write("---\n\n")
            
            # –ë–∞–∑–∞ –ª–∏–¥–æ–≤ (—Ç–∞–±–ª–∏—Ü–∞)
            f.write("## üìã –ë–∞–∑–∞ –ª–∏–¥–æ–≤\n\n")
            
            if self.results['relevant_vacancies']:
                f.write("| –í—Ä–µ–º—è | –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ | –ó–∞–ø—Ä–æ—Å | –ö–æ–Ω—Ç–∞–∫—Ç | –û—Ç–∫–ª–∏–∫ |\n")
                f.write("|-------|-------------|--------|---------|--------|\n")
                
                for v in self.results['relevant_vacancies']:
                    time_str = datetime.fromisoformat(v['date']).strftime('%H:%M')
                    direction = v['analysis'].get('specialization', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')
                    query_preview = v['text'][:50].replace('\n', ' ').replace('|', '\\|') + "..."
                    
                    # –õ–æ–≥–∏–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–æ–Ω—Ç–∞–∫—Ç–∞
                    contact_data = v['contact']
                    contact_link = contact_data.get('contact_link')
                    contact_value = contact_data.get('contact_value')
                    
                    # –ï—Å–ª–∏ —Å—Å—ã–ª–∫–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, admin_mention), –ø—Ä–æ–±—É–µ–º –ø–æ–¥—Å—Ç–∞–≤–∏—Ç—å ID –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
                    # –ù–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ ID –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø (–æ–±—ã—á–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –±–æ–ª—å—à–æ–µ —á–∏—Å–ª–æ, –Ω–µ -100...)
                    if not contact_link and contact_data.get('contact_type') == 'admin_mention' and v.get('sender_id'):
                        sid = v['sender_id']
                        if sid > 0: # ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –æ–±—ã—á–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
                            contact_link = f"tg://user?id={sid}"
                    
                    if contact_link and (contact_link.startswith('http') or contact_link.startswith('tg://')):
                        contact_display = f"[–ö–æ–Ω—Ç–∞–∫—Ç]({contact_link})"
                    elif contact_value:
                        contact_display = contact_value
                    else:
                        contact_display = "- –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω -"
                    
                    response = "-"  # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
                    
                    f.write(f"| {time_str} | {direction} | {query_preview} | {contact_display} | {response} |\n")
                
                f.write("\n---\n\n")
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö
            f.write("## üìù –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n\n")
            
            for i, v in enumerate(self.results['relevant_vacancies'], 1):
                spec = v['analysis']['specialization'].capitalize()
                priority = v['priority']
                f.write(f"## {i}. {spec} [{priority}]\n")
                f.write(f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** {v['channel']}\n")
                f.write(f"**–û–ø–ª–∞—Ç–∞:** {v.get('budget') or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'}\n")
                f.write(f"**–ö–æ–Ω—Ç–∞–∫—Ç:** {v['contact'].get('contact_value') or '–ù–µ –Ω–∞–π–¥–µ–Ω'}\n\n")
                f.write(f"### –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞:\n")
                f.write(f"{v['full_text']}\n\n")
                f.write("---\n\n")
            
            if self.results['irrelevant_messages']:
                f.write(f"## ‚ùå –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è ({len(self.results['irrelevant_messages'])})\n")
                f.write("–≠—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –±—ã–ª–∏ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω—ã, –Ω–æ –Ω–µ –ø—Ä–æ—à–ª–∏ —Ñ–∏–ª—å—Ç—Ä—ã:\n\n")
                
                for m in self.results['irrelevant_messages']:
                    reason = m.get('rejection_reason', '–ü—Ä–∏—á–∏–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞')
                    f.write(f"- **[{m['channel']}]**: {reason} (ID: {m['message_id']})\n")
        
        print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {filename}")

    def generate_full_unfiltered_report(self, filename: str):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –±–µ–∑ –∫–∞–∫–∏—Ö-–ª–∏–±–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
        filepath = settings.REPORTS_DIR / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"# üìú –ü–û–õ–ù–´–ô –î–ê–ú–ü –°–û–û–ë–©–ï–ù–ò–ô (–ë–ï–ó –§–ò–õ–¨–¢–†–û–í)\n\n")
            f.write(f"**–î–∞—Ç–∞:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
            f.write(f"**–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–∞–º–ø–µ:** {len(self.results['all_messages'])}\n\n")
            f.write("--- \n\n")
            
            for i, m in enumerate(self.results['all_messages'], 1):
                status = "‚úÖ –†–ï–õ–ï–í–ê–ù–¢–ù–û" if m['is_relevant'] else "‚ùå –ö–†–ê–°–ù–´–ô –§–ò–õ–¨–¢–†"
                f.write(f"### {i}. [{m['channel']}] (ID: {m['message_id']})\n")
                f.write(f"**–°—Ç–∞—Ç—É—Å:** {status} | **Score:** {m['relevance_score']}\n")
                if m['rejection_reason']:
                    f.write(f"**–ü—Ä–∏—á–∏–Ω–∞ —Ñ–∏–ª—å—Ç—Ä–∞:** {m['rejection_reason']}\n")
                f.write(f"\n**–¢–ï–ö–°–¢:**\n{m['full_text']}\n\n")
                f.write("--- \n\n")
        
        print(f"üìÑ –ü–æ–ª–Ω—ã–π –¥–∞–º–ø —Å–æ–∑–¥–∞–Ω: {filename}")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    parser = TelegramVacancyParser()
    await parser.initialize()

    print(f"üöÄ –ó–∞–ø—É—â–µ–Ω –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥...")
    
    while True:
        try:
            start_time = datetime.now()
            print(f"\n‚è∞ –ù–æ–≤—ã–π —Ü–∏–∫–ª —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {start_time.strftime('%H:%M:%S')}")
            
            cycle_parser = TelegramVacancyParser()
            await cycle_parser.parse_dialogs(hours_ago=24)
            
            today = datetime.now().strftime("%Y-%m-%d")
            cycle_parser.save_results(f"vacancies_{today}_monitor.json")
            cycle_parser.generate_markdown_report("report_today.md")
            cycle_parser.generate_full_unfiltered_report("full_dump_today.md")
            
            end_time = datetime.now()
            duration = end_time - start_time
            
            print(f"üèÅ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {duration}. –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥...")
            await asyncio.sleep(10)
            
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ: {e}")
            await asyncio.sleep(60)

if __name__ == "__main__":
    asyncio.run(main())
